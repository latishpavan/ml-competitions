}
mode(a)
mode(c(2, 2, 2, 1))
mode(c(2, 2, 2, 1, 1))
mode(c(2, 2, 2, 1, 1, 3, 3, 3, 3))
mode(c(2, 2, 2, 1, 1, 3, 3, 3, 3))
which.max(table(data))
sam <- c(2, 2, 2, 1, 1, 3, 3, 3, 3)
which.max(table(sam))
sam[which.max(table(sam))]
names(sam)[which.max(table(sam))]
fish <- which.max(table(sam))
fish
sam <- c(10, 10, 20)
mode(sam)
sam <- c(10, 10, 20, 20, 20)
mode(sam)
table(sam)
which.max(table(sam))
fish <- which.max(table(sam))
sam[fish]
names(sam)[fish]
names(fish)
as.numeric(names(fish))
mode <- function(data){
return(as.numeric(names([which.max(table(data))])))
}
mode <- function(data){
freq <- which.max(table(data))
as.numeric(names(freq))
}
mode <- function(data){
freq <- which.max(table(data))
names(freq)
}
mode(sam)
sa <- matrix(c(1, 2, 3), c(1, 3, 4))
sa
sa <- cbind(c(1, 1, 2), c(1, 2, 2))
sa
apply(sa, MARGIN = 2, mode)
seq_along(sam)
mode <- function(data){
freq <- which.max(table(data))
as.numeric(names(freq))
}
mode <- function(data, num = FALSE){
freq <- which.max(table(data))
ifelse(num, as.numeric(names(freq)), names(freq))
}
apply(sa, MARGIN = 2, mode, num = TRUE)
ensemble.predict <- function(data, models){
len <- nrow(data)
temp <- numeric(length = len)
for(model in models) {
mod_preds <- predict.train(object = model,
data = data,
type = "raw")
temp <- rbind(temp, mod_preds)
}
predictions <- apply(temp, MARGIN = 2, mode, num = TRUE)
return(predictions)
}
models <- c(model_nn, model_rf, model_gb)
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
ensemble.predict <- function(data, models){
len <- nrow(data)
temp <- numeric(length = len)
for(model in models) {
mod_preds <- predict.train(object = model,
data,
type = "raw")
temp <- rbind(temp, mod_preds)
}
predictions <- apply(temp, MARGIN = 2, mode, num = TRUE)
return(predictions)
}
library(caret)
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
models
model_rf
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
n
sample <- rbind(predictions_gb, predictions_rf, predictions_nn)
sample
lat <- apply(sample, 2, mode, num = TRUE)
lat
confusionMatrix(lat, validation.set[, outcame.name])
confusionMatrix(as.factor(lat), validation.set[, outcame.name])
as.factor(lat)
validation.set[,outcame.name]
lat <- lat - 1
lat
lat <- as.factor(lat)
lat
confusionMatrix(validation.set[, outcame.name], lat)
confusionMatrix(validation.set[, outcame.name], predictions_gb)
confusionMatrix(validation.set[, outcame.name], predictions_rf)
confusionMatrix(validation.set[, outcame.name], predictions_nn)
sample <- rbind(predictions_gb, predictions_rf)
lat <- as.factor(apply(sample, 2, mode, num = T) - 1)
lat
confusionMatrix(lat, validation.setp[, outcame.name])
confusionMatrix(lat, validation.set[, outcame.name])
ensemble.predict <- function(data, models){
len <- nrow(data)
temp <- numeric(length = len)
for(model in models) {
mod_preds <- predict.train(object = model,
data,
type = "raw")
temp <- rbind(temp, mod_preds)m
}
predictions <- apply(temp, MARGIN = 2, mode, num = TRUE)
return(predictions)
}
ensemble.predict <- function(data, models){
len <- nrow(data)
temp <- numeric(length = len)
for(model in models) {
mod_preds <- predict.train(object = model,
data,
type = "raw")
temp <- rbind(temp, mod_preds)m
}
predictions <- apply(temp, MARGIN = 2, mode, num = TRUE)
return(predictions)
}
ensemble.predict <- function(data, models){
len <- nrow(data)
temp <- numeric(length = len)
for(model in models) {
mod_preds <- predict.train(object = model,
data,
type = "raw")
temp <- rbind(temp, mod_preds)
}
predictions <- apply(temp, MARGIN = 2, mode, num = TRUE)
return(predictions)
}
ensemble.predict(validation.set[, best.features], models)
models <- list(model_nn, model_rf, model_gb)
ensemble.predict(validation.set[, best.features], models)
models <- list(model_rf, model_gb)
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
confusionMatrix(validation.set[, outcame.name], ensemble.preds)
ensemble.preds <- as.factor(ensemble.preds - 1)
confusionMatrix(validation.set[, outcame.name], ensemble.preds)
ensemble.preds <- as.factor(ensemble.preds)
ensemble.preds
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
ensemble.preds <- as.factor(ensemble.preds)
ensemble.preds
models <- list(model_rf, model_gb)
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
ensemble.preds
ensemble.predict <- function(data, models){
len <- nrow(data)
temp <- numeric(length = len)
for(model in models) {
mod_preds <- predict.train(object = model,
data,
type = "raw")
temp <- rbind(temp, mod_preds)
}
predictions <- apply(temp[1, ], MARGIN = 2, mode, num = TRUE)
return(predictions)
}
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
ensemble.predict <- function(data, models){
len <- nrow(data)
temp <- numeric(length = len)
for(model in models) {
mod_preds <- predict.train(object = model,
data,
type = "raw")
temp <- rbind(temp, mod_preds)
}
temp <- temp[2:len, ]
predictions <- apply(temp, MARGIN = 2, mode, num = TRUE)
return(predictions)
}
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
ensemble.predict <- function(data, models){
len <- nrow(data)
temp <- numeric(length = len)
for(model in models) {
mod_preds <- predict.train(object = model,
data,
type = "raw")
temp <- rbind(temp, mod_preds)
}
temp <- temp[2:length(models), ]
predictions <- apply(temp, MARGIN = 2, mode, num = TRUE)
return(predictions)
}
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
len <- nrow(data)
temp <- numeric(length = len)
debug(ensemble.predict)
debug(ensemble.predict)
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
temp
a <- matrix(1:9)
a
a <- matrix(1:9, 3, 3)
a
a[2:nrow(a), ]
ensemble.predict <- function(data, models){
len <- nrow(data)
temp <- numeric(length = len)
for(model in models) {
mod_preds <- predict.train(object = model,
data,
type = "raw")
temp <- rbind(temp, mod_preds)
}
temp <- temp[2:nrow(temp), ]
predictions <- apply(temp, MARGIN = 2, mode, num = TRUE)
return(predictions)
}
models <- list(model_rf, model_gb)
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
ensemble.preds
ensemble.preds <- as.factor(ensemble.preds - 1)
confusionMatrix(validation.set[, outcame.name], ensemble.preds)
final.ans <- ensemble.predict(test.data[:, best.features], models)
final.ans <- ensemble.predict(test.data[:, best.features], models)
traceback()
final.ans <- ensemble.predict(test.data[:, best.features], models)
final.ans <- ensemble.predict(test.data[, best.features], models)
submit <- data.frame(cbind(test.data$PassengerId, final.ans))
submit$final.ans <- submit$final.ans - 1
colnames(submit) <- c("PassengerId", "Survived")
write.csv(x = submit, file = "submit.csv", row.names = FALSE)
model_ada <- train(train.set[, best.features],
train.set[, outcame.name],
method = "adaboost",
trControl = fit.control,
tuneLength = 10)
model_ada
plot(train.data$Fare)
hist(train.data$Fare)
hist(train.data$Fare, breaks = 40, xlim = c(0, 400))
hist(train.data$Fare, breaks = 40, xlim = c(0, 400), col = "grey")
samp <- train.data$Fare
samp_norm <- (samp - mean(samp)) / sqrt(var(samp))
hist(samp_norm)
samp_norm
mean(samp_norm)
var(samp_norm)
var(samp)
hist(samp_norm, breaks = 40)
hist(samp_norm, breaks = 100)
models <- list(model_rf, model_gb, model_ada)
models <- list(model_rf, model_gb, model_ada)
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
ensemble.preds <- as.factor(ensemble.preds - 1)
confusionMatrix(validation.set[, outcame.name], ensemble.preds)
fares <- trimmed.data$Fare
trimmed.data$Fare <- (fares - mean(fares)) / sqrt(var(fares))
test.data <- trimmed.data[trimmed.data$isTrainFALSE == 1, ]
train.data <- trimmed.data[trimmed.data$isTrainTRUE == 1, ]
removes <- c("PassengerId", "isTrainFALSE", "isTrainTRUE",
"isfullDataTRUE", "isfullDataFALSE")
train.data <- train.data[, !colnames(train.data) %in% removes]
index <- createDataPartition(train.data$Survived, p = 0.75, list = F)
train.set <- train.data[index, ]
validation.set <- train.data[-index, ]
control <- rfeControl(functions = rfFuncs,
method = "repeatedcv",
repeats = 3,
number = 3,
verbose = FALSE)
outcame.name <- "Survived"
predictors <- colnames(train.data)[!colnames(train.data) %in% outcame.name]
features <- rfe(train.set[, predictors], train.set[, outcame.name],
rfeControl = control)
best.features <- features$optVariables
fit.control <- trainControl(method = "repeatedcv",
repeats = 3,
number = 5)
grid <- expand.grid(mtry = c(10, 20, 30, 40))
model_rf <- train(train.set[, best.features],
train.set[, outcame.name],
method = "rf",
trControl = fit.control,
tuneLength = 10)
model_gb <- train(train.set[, best.features],
train.set[, outcame.name],
method = "gbm",
trControl = fit.control,
tuneLength = 10)
predictions_gb <- predict.train(object = model_gb,
validation.set[, best.features],
type = "raw")
confusionMatrix(validation.set[, outcame.name], predictions_gb)
predictions_rf <- predict.train(object = model_rf,
validation.set[, best.features],
type = "raw")
confusionMatrix(validation.set[, outcame.name], predictions_rf)
model_ada <- train(train.set[, best.features],
train.set[, outcame.name],
method = "adaboost",
trControl = fit.control,
tuneLength = 3)
predictions_ada <- predict.train(object = model_ada,
validation.set[, best.features],
type = "raw")
confusionMatrix(validation.set[, outcame.name], predictions_ada)
models <- list(model_rf, model_gb, model_ada)
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
ensemble.preds <- as.factor(ensemble.preds - 1)
confusionMatrix(validation.set[, outcame.name], ensemble.preds)
models <- list(model_rf, model_gb)
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
ensemble.preds <- as.factor(ensemble.preds - 1)
confusionMatrix(validation.set[, outcame.name], ensemble.preds)
final.ans <- ensemble.predict(test.data[, best.features], models)
submit <- data.frame(cbind(test.data$PassengerId, final.ans))
submit$final.ans <- submit$final.ans - 1
colnames(submit) <- c("PassengerId", "Survived")
write.csv(x = submit, file = "submit.csv", row.names = FALSE)
models <- list(model_rf)
ensemble.preds <- ensemble.predict(validation.set[, best.features],
models)
confusionMatrix(validation.set[, outcame.name], predictions_rf)
final.ans <- predict.train(object = model_rf,
test.data[, best.features],
type = "raw")
submit <- data.frame(cbind(test.data$PassengerId, final.ans))
submit$final.ans <- submit$final.ans - 1
colnames(submit) <- c("PassengerId", "Survived")
write.csv(x = submit, file = "submit.csv", row.names = FALSE)
model_xgb <- train(train.set[, best.features],
train.set[, outcame.name],
method = "xgboost",
trControl = fit.control,
tuneLength = 10)
model_ada <- train(train.set[, best.features],
train.set[, outcame.name],
method = "adaboost",
trControl = fit.control,
tuneLength = 10)
model_xgb <- train(train.set[, best.features],
train.set[, outcame.name],
method = "xgbTree",
trControl = fit.control,
tuneLength = 10)
model_ada <- train(train.set[, best.features],
train.set[, outcame.name],
method = "adaboost",
trControl = fit.control,
tuneLength = 10)
model_xgb
xgb <- predict.train(model_xgb, test.data[, best.features])
xgb
confusionMatrix(xgb, test.data[, best.features])
confusionMatrix(xgb, test.data[, outcome.name])
confusionMatrix(xgb, test.data[, "Survived"])
save.image("E:/machine learning competitions/kaggle/titanic_survival/titanicData.R.RData")
x <- rnorm(1000)
hist(x, breaks = 100)
hist(x, breaks = 40)
hist(x)
x
x <- rnorm(1000, mean = 20, sd = 5)
x
hist(x, breaks = 100)
hist(x)
hist(x, breaks = 100, xlim = c(20, 21))
x <- rnorm(100, mean = 20, sd = 5)
hist(x)
hist(x)
hist(x, breaks = 100)
subset(x, 10)
subset(x)
subset(x, TRUE)
subset(x, TRUE, 10)
sample
x <- rnorm(1000)
hist(x, breaks = 100)
x <- rbinom(1000)
x <- rbinom(1000, size = 2, prob = 0.5)
z
hist(x, breaks = 100)
x <- runif(1000)
hist(x, breaks = 100)
sample(x, 3)
seq_len(2)
num <- 30
size <- 40
sampMeans <- numeric(num)
for(i in seq_len(num)){
s <- sample(x, size)
sampMeans[i] <- mean(s)
}
hist(sampMeans, breaks = 100)
num <- 300
size <- 40
sampMeans <- numeric(num)
for(i in seq_len(num)){
s <- sample(x, size)
sampMeans[i] <- mean(s)
}
hist(sampMeans, breaks = 100)
mean(sampMeans)
mean(x)
var(x) / size
var(sampMeans)
y <- sample(-1:1, 10)
y <- rnorm(100, mean = 0, sd = 1)
y
range(-1, 1)
mean(y)
x <- y + 1
cor.test(x, y)
cor(x, y)
x <- 2 * y + 1
cor(x, y)
scatter()
scatter.smooth(x, y)
cor(x, y, method = "spearmna")
cor(x, y, method = "spearman")
x <- exp(x)
cor(x, y, method = "spearman")
x <- exp(-y)
cor(x, y, method = "spearman")
cov(x, y)
x <- 2* y + 1
cov(x, y)
x <- 2* y + 100
cov(x, y)
x <- 3* y + 100
cov(x, y)
x <- exp(y)
cov(x, y)
x <- 300* y + 100
cov(x, y)
cor(x, y)
Map()
Map(function(x) x^2)
Map(function(x) x^2, c(1, 2, 3, 4))
Map(function(x) x^2, c(1, 2, 3, 4), c(4, 5, 6))
Map(function(x) x^2, c(1, 2, 3, 4))
d <- function(...){
print(dots)
}
d(1, 2, 3)
Map(function(x) x^2, c(1, 2, 3, 4))
Filter(function(x) x > 0, c(-1, -2, 3, 4))
path <- "E:/machine learning competitions/kaggle/mnist/train.csv"
setwd(path)
path <- "E:/machine learning competitions/kaggle/mnist"
setwd(path)
trainData <- read.csv("train.csv", header = TRUE, stringsAsFactors = F)
testData <- read.csv("test.csv", stringsAsFactors = FALSE)
str(trainData)
library(keras)
library(caret)
index <- createDataPartition(trainData$label, p = 0.75)
train <- trainData[index, ]
index <- createDataPartition(trainData$label, p = 0.75, list = FALSE)
train <- trainData[index, ]
x <- c(1, 2, 3, 4, 5)
x[-1]
x[-2]
index
x[-3]
x_train <- train[, -label]
outcome <- "label"
x_train <- train[, !colnames(train) %in% outcome]
y_train <- train[, outcome]
colnames(x_train)
colnames(x_train)[1:5]
colnames(y_train)
y_train
x_test <- test[, !colnames(test) %in% outcome]
y_test <- test[, outcome]
test <- trainData[-index, ]
x_test <- test[, !colnames(test) %in% outcome]
y_test <- test[, outcome]
maxIntensity <- 255
x_train <- x_train / maxIntensity
x_test <- x_test / maxIntensity
y_train <- to_categorical(y_train, num_classes = 10)
y_test <- to_categorical(y_test, num_classes = 10)
install_keras(method = "conda", tensorflow = "gpu")
save.image("E:/machine learning competitions/kaggle/mnist/mnistdata.RData")
library(keras)
install_keras(method = "conda", tensorflow = "gpu")
install_keras(method = "conda", tensorflow = "gpu")
library(tensorflow)
install_tensorflow(method = "conda", version = "1.1.0-gpu")
